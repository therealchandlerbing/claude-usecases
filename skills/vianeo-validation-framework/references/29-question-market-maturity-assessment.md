# Vianeo 29-Question Market Maturity Assessment

**Purpose:** Evaluates market readiness across the five Vianeo framework dimensions: Legitimacy, Desirability, Acceptability, Feasibility, and Viability.

**Assessment Type:** Market Validation / Vianeo Framework Alignment
**Rating Scale:** 1-5 (Absolutely / Rather / Rather not / Not at all / Don't know)
**Framework Alignment:** Direct mapping to Vianeo's 5-dimension validation model

---

## Table of Contents

1. [Rating Scale Guide](#rating-scale-guide)
2. [Assessment Questions (Q1-Q29)](#assessment-questions)
3. [Dimension Mapping](#dimension-mapping)
4. [Scoring and Interpretation](#scoring-and-interpretation)
5. [Evidence-Based Scoring Guidance](#evidence-based-scoring-guidance)

---

## Rating Scale Guide

### Scale Definition

**5 = Absolutely**
- Strong evidence exists
- Validated through multiple sources
- Clearly documented
- High confidence level

**4 = Rather**
- Good progress with some validation
- Minor gaps remain
- Generally confident
- Evidence available but not comprehensive

**3 = Rather not**
- Preliminary work done
- Lacks validation or depth
- Low confidence
- Hypothesis stage primarily

**2 = Not at all**
- Little to no work completed
- Significant gaps
- Awareness exists but not addressed
- No concrete progress

**1 = Don't know**
- No information available
- Area not yet explored
- Requires investigation
- Information gap identified

---

## Assessment Questions

### LEGITIMACY Dimension

#### Q8. You have identified one (or more) market(s) or field(s) of application for your project.

**Score 5 (Absolutely):**
- Specific markets clearly defined (e.g., "hospital-based cognitive assessment for adults 65+" not just "healthcare")
- Multiple application fields identified and prioritized
- Market selection criteria documented

**Score 4 (Rather):**
- Primary market identified with reasonable specificity
- Secondary markets under consideration
- Basic market definition complete

**Score 3 (Rather not):**
- Broad market category identified (e.g., "healthcare" or "education")
- Limited specificity or focus
- Multiple possibilities, no prioritization

**Score 2 (Not at all):**
- Very vague market ideas (e.g., "help people")
- No clear application field
- Market undefined

**Score 1 (Don't know):**
- Market not yet considered
- No analysis conducted

**Evidence Examples:**
- Market definition document
- TAM/SAM/SOM analysis
- Target segment descriptions
- Market prioritization matrix

---

#### Q13. Your solution aims to solve a real problem. You have validated with a number of people that this problem is a real thorn in their side (and not only for yourself).

**Score 5 (Absolutely):**
- 10+ people confirmed problem severity
- Quantified pain points documented (time, cost, frequency)
- Problem validated across different customer segments
- Evidence of urgency and current inadequate solutions

**Score 4 (Rather):**
- 5-9 people confirmed problem
- Some quantification available
- General consensus on problem severity
- Current workarounds identified

**Score 3 (Rather not):**
- 2-4 people mentioned problem
- Mostly qualitative feedback
- Problem acknowledgment but unclear severity
- Limited validation

**Score 2 (Not at all):**
- Assumed problem based on personal experience
- 0-1 external validations
- No evidence of widespread pain
- Hypothesis only

**Score 1 (Don't know):**
- Problem not yet validated externally
- No customer conversations conducted

**Evidence Examples:**
- Interview transcripts with pain point quotes
- Survey results showing problem frequency/severity
- Current solution cost/time data
- Customer willingness-to-pay signals

---

### DESIRABILITY Dimension

#### Q2. You have identified people with strong needs AND who are looking for solutions to better meet their needs.

**Score 5 (Absolutely):**
- Specific requester segments identified with documented behaviors
- Evidence of active solution-seeking (budget allocated, trials underway, RFPs issued)
- Current inadequate solutions documented
- Unmet needs quantified

**Score 4 (Rather):**
- Requester segments identified
- Some evidence of solution-seeking behavior
- Needs expressed in conversations
- General dissatisfaction with status quo noted

**Score 3 (Rather not):**
- General user types identified
- Assumed needs, limited validation
- No clear evidence of active searching
- Hypothetical need state

**Score 2 (Not at all):**
- Vague user definitions
- No validation of need strength
- No evidence of solution-seeking
- Assumed problem awareness

**Score 1 (Don't know):**
- Users not yet identified
- No needs research conducted

**Evidence Examples:**
- Requester persona documents
- Needs statements with validation source count
- Current solution cost/limitation data
- Buyer journey mapping showing active search

---

#### Q4. You have defined your offer and its features according to the needs that are not met today.

**Score 5 (Absolutely):**
- Feature set directly maps to validated unmet needs
- Features prioritized by need severity/frequency
- Explicit traceability: Feature → Need → Evidence
- Customer feedback incorporated into feature definition

**Score 4 (Rather):**
- Core features aligned with identified needs
- Some feature-need mapping documented
- Primary unmet needs addressed
- Basic prioritization complete

**Score 3 (Rather not):**
- Features defined but connection to needs unclear
- Assumed alignment without validation
- Technology-driven more than need-driven
- Limited customer input on features

**Score 2 (Not at all):**
- Features defined independent of customer needs
- No traceability to specific unmet needs
- Technology-first approach
- No customer validation

**Score 1 (Don't know):**
- Offer features not yet defined
- No needs analysis conducted

**Evidence Examples:**
- Feature-need traceability matrix
- Customer interview feedback on proposed features
- Prioritization framework (need severity vs. competitive gap)
- Feature validation test results

---

#### Q5. You target the customers who are the easiest to reach and the most strategic to help you enter the market.

**Score 5 (Absolutely):**
- Specific early adopter segment identified with access plan
- Strategic value documented (referenceable, influential, scalable)
- Accessibility confirmed (warm intros, existing relationships, clear path)
- Beachhead strategy defined and validated

**Score 4 (Rather):**
- Target customer segment identified
- Some access pathways mapped
- Strategic reasoning documented
- Reachability assessed

**Score 3 (Rather not):**
- General target customer defined
- Access strategy not clear
- Strategic value assumed
- Limited pathway planning

**Score 2 (Not at all):**
- Broad customer definition
- No accessibility assessment
- Strategic targeting not considered
- Opportunistic approach

**Score 1 (Don't know):**
- Target customers not yet identified
- No market entry strategy

**Evidence Examples:**
- Early adopter profile document
- Access pathway map (warm intros, partnerships, events)
- Strategic value assessment (references, case studies, scale path)
- Beachhead-to-expansion plan

---

#### Q6. You have identified and studied the solutions currently used to meet the expressed needs, competitor or alternative.

**Score 5 (Absolutely):**
- Comprehensive competitive analysis (5+ solutions)
- Direct and indirect competitors mapped
- Alternative approaches documented (manual, workarounds, adjacent solutions)
- Pricing, features, strengths/weaknesses documented

**Score 4 (Rather):**
- Main competitors identified (3-4)
- Basic feature/price comparison
- Some alternatives noted
- Gaps and opportunities identified

**Score 3 (Rather not):**
- 1-2 competitors identified
- Surface-level understanding
- Limited alternative solution mapping
- No systematic analysis

**Score 2 (Not at all):**
- Competitor awareness but no analysis
- No study of alternatives
- Assumed competitive landscape
- No documentation

**Score 1 (Don't know):**
- Competitive landscape not explored
- No solution mapping conducted

**Evidence Examples:**
- Competitive analysis matrix
- Alternative solution documentation
- Customer feedback on current solutions
- Win/loss analysis (if sales attempted)

---

#### Q7. You have checked through direct interviews, with at least 5 people with the same profile, that they express needs.

**Score 5 (Absolutely):**
- 10+ interviews with consistent persona
- Structured interview protocol used
- Needs validated across majority (75%+)
- Documented transcripts or detailed notes
- Quantified needs (frequency, severity, willingness to pay)

**Score 4 (Rather):**
- 5-9 interviews with similar profiles
- Consistent needs emerged
- Good documentation
- Some quantification

**Score 3 (Rather not):**
- 3-4 interviews
- Similar profiles but some variation
- Needs mentioned but not deeply validated
- Basic notes available

**Score 2 (Not at all):**
- 1-2 interviews only
- Varied profiles, not consistent persona
- Weak needs expression
- Limited documentation

**Score 1 (Don't know):**
- No direct interviews conducted
- Needs assumed, not validated

**Evidence Examples:**
- Interview transcripts or detailed notes
- Needs validation matrix (need × interview count)
- Persona document with evidence sources
- Quantified pain points

---

#### Q9. You have defined your product/market fit: you provide each customer segment you target an offer that meets their needs.

**Score 5 (Absolutely):**
- Clear segment-specific value propositions
- Customer validation for each segment (3+ per segment)
- Feature set tailored by segment
- Pricing/packaging aligned with segment needs
- Evidence of customer traction or strong interest

**Score 4 (Rather):**
- Value proposition defined per segment
- Some customer validation
- Feature differentiation by segment
- Good alignment rationale

**Score 3 (Rather not):**
- Single value proposition for all segments
- Assumed fit, limited validation
- Minimal segmentation
- Generic offering

**Score 2 (Not at all):**
- No clear product/market fit articulation
- Offering not tailored to segments
- No customer validation
- Technology-first approach

**Score 1 (Don't know):**
- Product/market fit not yet defined
- Segmentation not completed

**Evidence Examples:**
- Segment-specific value proposition statements
- Customer validation results by segment
- Feature/pricing matrix by segment
- Traction metrics (if available)

---

#### Q11. Customers will easily perceive the interest of your offer because it brings them real added value compared to existing solutions (new offer, new market, competitive advantage).

**Score 5 (Absolutely):**
- Quantified value proposition (2x better, 50% cost reduction, etc.)
- Customer testimonials confirming perceived value
- Clear differentiation validated by customers
- Competitive advantage documented and tested

**Score 4 (Rather):**
- Value proposition defined
- Customer feedback confirms interest
- Differentiation articulated
- Some competitive advantage evidence

**Score 3 (Rather not):**
- Value proposition stated
- Differentiation assumed
- Limited customer validation
- Competitive advantage unclear

**Score 2 (Not at all):**
- Unclear value proposition
- No differentiation evidence
- Parity with existing solutions
- No customer validation

**Score 1 (Don't know):**
- Value proposition not defined
- Competitive positioning unclear

**Evidence Examples:**
- Quantified value proposition
- Customer quotes on perceived value
- A/B tests or preference studies
- Competitive differentiation validation

---

#### Q12. You regularly test your offer with users, whatever its stage of development.

**Score 5 (Absolutely):**
- Structured testing program in place
- Weekly or bi-weekly user testing
- Documented feedback loop
- Iterative improvements based on testing
- Multiple testing methods (interviews, prototypes, pilots)

**Score 4 (Rather):**
- Regular testing (monthly)
- Feedback documented
- Some iteration based on feedback
- Testing methodology defined

**Score 3 (Rather not):**
- Occasional testing
- Ad hoc feedback collection
- Limited iteration
- No formal process

**Score 2 (Not at all):**
- Rarely or never test with users
- No testing process
- Development in isolation
- Assumed user needs

**Score 1 (Don't know):**
- No testing conducted yet
- No users engaged

**Evidence Examples:**
- Testing schedule/calendar
- User feedback repository
- Product iteration changelog linked to feedback
- Testing protocols and scripts

---

#### Q21. Your offer meets key needs better than existing/competitive solutions.

**Score 5 (Absolutely):**
- Head-to-head comparison completed with customers
- Quantified superiority on key dimensions
- Customer preference validated (choice tests, pilots)
- Win/loss analysis confirms advantage
- Evidence of customer switching

**Score 4 (Rather):**
- Customer feedback indicates preference
- Some comparative data
- Advantages on key dimensions identified
- Good supporting evidence

**Score 3 (Rather not):**
- Claimed advantages
- Limited comparative validation
- Customer feedback mixed
- No preference testing

**Score 2 (Not at all):**
- No evidence of superiority
- Parity or disadvantage on key dimensions
- Customer feedback not favorable
- No comparative testing

**Score 1 (Don't know):**
- Comparison not conducted
- Competitive positioning unclear

**Evidence Examples:**
- Comparative testing results
- Customer preference data
- Win/loss analysis
- Feature comparison matrix with customer ratings

---

#### Q22. You have tested your products and services with at least 3 customers per segment: they have understood what you are selling and have shown interest.

**Score 5 (Absolutely):**
- 5+ customers per segment tested
- Clear comprehension validated
- Strong interest signals (LOI, pilot agreement, deposit)
- Documented feedback per segment
- Value proposition resonates

**Score 4 (Rather):**
- 3-4 customers per segment
- Good comprehension
- Interest expressed
- Positive feedback

**Score 3 (Rather not):**
- 1-2 customers per segment
- Some comprehension issues
- Mild interest
- Mixed feedback

**Score 2 (Not at all):**
- Less than 1 customer per segment
- Comprehension challenges
- Limited interest
- Weak validation

**Score 1 (Don't know):**
- No customer testing conducted
- Segments not validated

**Evidence Examples:**
- Customer testing log by segment
- Comprehension test results (can they explain back?)
- Interest indicators (next steps, commitments)
- Feedback documentation

---

#### Q25. You can accurately describe the profiles of people who express needs in your market, their behaviours and their expectations.

**Score 5 (Absolutely):**
- Detailed persona documents (4-layer structure)
- Based on 10+ interviews per persona
- Specific behaviors documented with evidence
- Quantified expectations and decision criteria
- Current solution usage patterns mapped

**Score 4 (Rather):**
- Persona profiles developed
- 5-9 interviews per persona
- Good behavioral detail
- Expectations documented
- Some quantification

**Score 3 (Rather not):**
- Basic persona outlines
- 3-4 interviews
- Generic behaviors
- Assumed expectations
- Limited specificity

**Score 2 (Not at all):**
- Vague user descriptions
- Minimal validation (0-2 interviews)
- No behavioral detail
- Expectations unclear

**Score 1 (Don't know):**
- User profiles not developed
- No research conducted

**Evidence Examples:**
- Persona documents with evidence
- Behavioral pattern documentation
- Decision criteria and expectations mapped
- Current solution usage data

---

#### Q28. You are able to prioritise people according to their expectation for a new solutions, those who express strong and very poorly met needs.

**Score 5 (Absolutely):**
- Needs qualification matrix completed
- Importance vs. satisfaction scored for each segment
- Early adopter segment clearly identified
- Prioritization validated with evidence
- Strategic sequencing plan defined

**Score 4 (Rather):**
- Prioritization framework applied
- Early adopters identified
- Some quantification
- Reasonable prioritization logic

**Score 3 (Rather not):**
- Basic prioritization attempted
- Limited validation
- Assumed priorities
- No systematic framework

**Score 2 (Not at all):**
- No prioritization
- All segments treated equally
- No early adopter identification
- Opportunistic approach

**Score 1 (Don't know):**
- Prioritization not considered
- Segmentation incomplete

**Evidence Examples:**
- Needs qualification matrix (importance × satisfaction)
- Early adopter profile and identification
- Prioritization framework documentation
- Strategic sequencing plan

---

### ACCEPTABILITY Dimension

#### Q3. You know the market players in your ecosystem: you are able to name a number of them (not just your clients and competitors).

**Score 5 (Absolutely):**
- Comprehensive ecosystem map (20+ players)
- Includes influencers, regulators, complementors, suppliers, partners
- Relationships and dynamics documented
- Strategic positioning clear

**Score 4 (Rather):**
- Good ecosystem mapping (10-19 players)
- Key player types identified
- Relationships understood
- Main dynamics mapped

**Score 3 (Rather not):**
- Basic ecosystem awareness (5-9 players)
- Mostly customers and competitors
- Limited relationship mapping
- Surface-level understanding

**Score 2 (Not at all):**
- Minimal ecosystem knowledge (1-4 players)
- Only most obvious players identified
- No relationship mapping
- Isolated perspective

**Score 1 (Don't know):**
- Ecosystem not explored
- No player mapping

**Evidence Examples:**
- Ecosystem map diagram
- Player profiles with roles and relationships
- Strategic positioning document
- Partnership or influence strategy

---

#### Q10. Regulations (current or future) may help your project to grow (legislation, standards...).

**Score 5 (Absolutely):**
- Specific favorable regulations identified
- Regulatory trends support project (new mandates, incentives)
- Timeline and impact quantified
- Strategy to leverage regulations defined

**Score 4 (Rather):**
- Favorable regulatory environment identified
- Some supporting trends
- General positive outlook
- Basic strategy to leverage

**Score 3 (Rather not):**
- Neutral regulatory environment
- No clear supportive regulations
- Assumed regulatory stability
- No leveraging strategy

**Score 2 (Not at all):**
- Regulations not helpful
- No supportive trends identified
- Regulatory environment unclear
- No analysis conducted

**Score 1 (Don't know):**
- Regulatory landscape not explored
- No research conducted

**Evidence Examples:**
- Regulatory analysis document
- Specific regulations/standards identified
- Timeline for regulatory changes
- Strategy to leverage favorable regulations

---

#### Q17. You have identified the players potentially unfavourable to your project.

**Score 5 (Absolutely):**
- Potential opponents clearly identified with motivations
- Risk assessment and mitigation plan developed
- Stakeholder engagement strategy for opposition
- Monitoring plan in place

**Score 4 (Rather):**
- Key opposition players identified
- Motivations understood
- Some risk mitigation planned
- Awareness of dynamics

**Score 3 (Rather not):**
- Possible opposition considered
- Limited identification or analysis
- No mitigation plan
- Surface awareness

**Score 2 (Not at all):**
- Opposition not identified
- No risk analysis
- Assumed no resistance
- No planning

**Score 1 (Don't know):**
- Not yet considered
- No stakeholder analysis

**Evidence Examples:**
- Opposition stakeholder analysis
- Risk and mitigation matrix
- Stakeholder engagement strategy
- Monitoring and response plan

---

#### Q20. You are able to represent the organisation of your market: identify groups of players (companies, organisations or individuals) according to their positions and link them together according to the nature of their links (clients/suppliers, financiers, influencers...).

**Score 5 (Absolutely):**
- Comprehensive market organization map
- Player groups clearly defined with relationships
- Value flows and influence mapped
- Strategic position identified
- Validated with industry experts

**Score 4 (Rather):**
- Good market structure understanding
- Key player groups and relationships identified
- Value flows mapped
- Strategic implications clear

**Score 3 (Rather not):**
- Basic market structure outlined
- Main groups identified
- Simple relationship mapping
- Limited strategic analysis

**Score 2 (Not at all):**
- Vague market understanding
- Player groups unclear
- Relationships not mapped
- No strategic positioning

**Score 1 (Don't know):**
- Market organization not explored
- No mapping conducted

**Evidence Examples:**
- Market organization diagram
- Player group definitions
- Relationship and value flow mapping
- Strategic positioning analysis

---

#### Q23. You have identified market players who will support your project.

**Score 5 (Absolutely):**
- Specific supporters identified with commitments
- Support types documented (advocacy, partnership, investment, referrals)
- Relationships established with evidence
- Supporter engagement plan active

**Score 4 (Rather):**
- Supporters identified
- Expressed interest documented
- Some relationship development
- Support types defined

**Score 3 (Rather not):**
- Potential supporters identified
- Preliminary conversations
- Interest assumed
- Limited engagement

**Score 2 (Not at all):**
- No supporters identified
- No outreach conducted
- Assumed support
- No relationships developed

**Score 1 (Don't know):**
- Support not yet considered
- No stakeholder engagement

**Evidence Examples:**
- Supporter list with commitment types
- Partnership or advocacy agreements
- Letters of support
- Engagement plan and status

---

#### Q24. Regulations (current or future) can have a strong negative influence on your project (legislation, standards...).

**Score 5 (Absolutely) - REVERSE SCORED:**
- Note: Lower score is better on this question
- Comprehensive regulatory analysis shows minimal risk
- Mitigation plans for any identified risks
- Clear regulatory pathway validated

**Score interpretation:**
- 5 = Significant regulatory barriers identified
- 4 = Some regulatory challenges
- 3 = Moderate regulatory complexity
- 2 = Minimal regulatory risk
- 1 = Regulatory landscape unknown

**Evidence Examples:**
- Regulatory risk assessment
- Compliance requirements analysis
- Mitigation strategies for identified risks
- Regulatory pathway documentation

---

### FEASIBILITY Dimension

#### Q1. You have solid and tangible resources (team, network, skills, patents, finances, equipment...) to launch and carry out this project.

**Score 5 (Absolutely):**
- Complete resource inventory documented
- Team with all necessary skills committed
- Sufficient funding secured for next 12-24 months
- IP protection in place or strategy clear
- Equipment/infrastructure access confirmed
- Strong network documented

**Score 4 (Rather):**
- Key resources identified and committed
- Core team in place
- Funding secured for 6-12 months
- Main IP and infrastructure addressed
- Good network access

**Score 3 (Rather not):**
- Some resources available
- Partial team commitment
- Limited funding (3-6 months)
- IP and infrastructure gaps
- Developing network

**Score 2 (Not at all):**
- Minimal resources secured
- Team incomplete or uncommitted
- Funding insufficient (<3 months)
- Significant resource gaps
- Limited network

**Score 1 (Don't know):**
- Resource assessment not completed
- Availability unclear

**Evidence Examples:**
- Resource inventory (team, funding, IP, equipment)
- Team commitment documentation
- Funding sources and runway
- Network map and access agreements

---

#### Q15. You are considering using technical partners to develop part of your offer in order to concentrate your effort on your core project.

**Score 5 (Absolutely):**
- Make vs. buy analysis completed
- Core competencies clearly defined
- Partnership strategy for non-core elements
- Potential partners identified with preliminary agreements
- Risk mitigation for dependencies

**Score 4 (Rather):**
- Partnership strategy defined
- Core vs. non-core identified
- Potential partners identified
- Good strategic rationale

**Score 3 (Rather not):**
- Considering partnerships
- Preliminary assessment
- Limited partner identification
- Unclear strategy

**Score 2 (Not at all):**
- Planning to build everything internally
- No partnership strategy
- Core competencies not defined
- Not considering partnerships

**Score 1 (Don't know):**
- Make vs. buy not yet considered
- Strategy undefined

**Evidence Examples:**
- Make vs. buy analysis
- Core competency definition
- Partnership strategy document
- Potential partner pipeline

---

#### Q16. You have formed a fully committed team to carry out this project.

**Score 5 (Absolutely):**
- Complete team with all necessary roles
- Full-time commitment from key members
- Equity/incentive alignment
- Track record of team working together
- Formal agreements in place

**Score 4 (Rather):**
- Core team committed
- Key roles filled
- Good commitment level (part-time acceptable if organized)
- Some incentive alignment
- Basic agreements

**Score 3 (Rather not):**
- Partial team
- Mixed commitment levels
- Some key gaps
- Limited formal agreements
- Developing cohesion

**Score 2 (Not at all):**
- Team incomplete
- Low commitment levels
- Significant gaps
- No formal structure
- Limited cohesion

**Score 1 (Don't know):**
- Team formation not yet addressed
- Commitment unclear

**Evidence Examples:**
- Team roster with roles and commitment levels
- Equity/option grants
- Employment or advisory agreements
- Team track record documentation

---

#### Q18. You have differentiating assets, i.e. capacities that only you have to carry out this project (e.g. expertise, patent, prototype, partnership...).

**Score 5 (Absolutely):**
- Multiple differentiating assets identified
- Assets protected (patents, contracts, unique data)
- Competitive moat clearly articulated
- Evidence of uniqueness (patents granted, exclusive partnerships, proprietary data)
- Barriers to replication documented

**Score 4 (Rather):**
- Key differentiating assets identified
- Some protection in place
- Competitive advantage articulated
- Good defensibility

**Score 3 (Rather not):**
- Some assets identified
- Limited protection
- Unclear differentiation
- Weak defensibility

**Score 2 (Not at all):**
- No clear differentiating assets
- Easy to replicate
- No competitive moat
- Generic capabilities

**Score 1 (Don't know):**
- Assets not yet identified
- Differentiation unclear

**Evidence Examples:**
- Patent portfolio or applications
- Exclusive partnership agreements
- Proprietary data or algorithms
- Unique expertise documentation
- Competitive moat analysis

---

#### Q26. You have the necessary means to develop your offer.

**Score 5 (Absolutely):**
- Complete development plan with resource allocation
- All development resources secured (funding, team, infrastructure)
- Timeline realistic and achievable
- Risk mitigation for development challenges
- Track record of development capability

**Score 4 (Rather):**
- Development plan defined
- Key resources secured
- Reasonable timeline
- Main capabilities in place

**Score 3 (Rather not):**
- Basic development plan
- Some resource gaps
- Timeline uncertain
- Capability gaps identified

**Score 2 (Not at all):**
- Significant resource gaps
- Development capability unclear
- No clear plan
- High execution risk

**Score 1 (Don't know):**
- Development requirements not assessed
- Resource needs unclear

**Evidence Examples:**
- Development roadmap with milestones
- Resource allocation plan
- Funding committed for development
- Team capability assessment
- Risk and mitigation plan

---

### VIABILITY Dimension

#### Q14. You have defined your revenue streams: i.e. how you will earn money (sales per unit, per subscription, per time spent...).

**Score 5 (Absolutely):**
- Multiple revenue streams identified and quantified
- Revenue model tested with customers (pricing, packaging)
- Unit economics validated
- Revenue projections based on customer data
- Scalability demonstrated

**Score 4 (Rather):**
- Revenue streams clearly defined
- Some customer validation
- Reasonable unit economics
- Projections based on assumptions with some data

**Score 3 (Rather not):**
- Basic revenue model outlined
- Limited validation
- Unit economics assumed
- Projections largely hypothetical

**Score 2 (Not at all):**
- Revenue model unclear
- No customer validation
- Unit economics unknown
- No projections

**Score 1 (Don't know):**
- Revenue model not yet defined
- Monetization unclear

**Evidence Examples:**
- Revenue model documentation
- Pricing tested with customers
- Unit economics analysis
- Revenue projections with assumptions
- Customer willingness-to-pay data

---

#### Q19. You have tested your revenue model with at least 3 potential customers.

**Score 5 (Absolutely):**
- 10+ customers tested on pricing/model
- Customer acceptance documented
- Pricing sensitivity understood
- Revenue model validated and refined
- Evidence of purchases or commitments at stated price

**Score 4 (Rather):**
- 5-9 customers tested
- General acceptance
- Some pricing feedback
- Model validated

**Score 3 (Rather not):**
- 3-4 customers tested
- Mixed feedback
- Pricing not finalized
- Limited validation

**Score 2 (Not at all):**
- 0-2 customers tested
- No validation
- Assumed pricing
- Hypothetical model

**Score 1 (Don't know):**
- Revenue model not tested
- No customer engagement on pricing

**Evidence Examples:**
- Customer feedback on pricing
- Pricing test results
- Purchase commitments or contracts
- Willingness-to-pay analysis
- Pricing iteration based on feedback

---

#### Q27. You are able to express your value proposition in one sentence for each type of customers: why they should buy your solution.

**Score 5 (Absolutely):**
- Clear one-sentence value proposition per segment
- Customer-validated language
- Quantified value included
- Differentiation clear
- Tested and resonates with customers

**Score 4 (Rather):**
- Value propositions defined per segment
- Clear and concise
- Customer feedback incorporated
- Differentiation articulated

**Score 3 (Rather not):**
- Value propositions drafted
- Generic or wordy
- Limited customer validation
- Differentiation unclear

**Score 2 (Not at all):**
- No clear value propositions
- Cannot articulate concisely
- Not segment-specific
- No customer validation

**Score 1 (Don't know):**
- Value propositions not developed
- Customer value unclear

**Evidence Examples:**
- Value proposition statements by segment
- Customer feedback on messaging
- A/B testing results (if applicable)
- Sales pitch documentation

---

#### Q29. You have the means to reach your customers (sales force, marketing and communication budget...).

**Score 5 (Absolutely):**
- Complete go-to-market plan with resources
- Sales and marketing budget allocated
- Channels identified and tested
- CAC (Customer Acquisition Cost) validated
- Distribution partnerships in place
- Team or agency secured

**Score 4 (Rather):**
- GTM plan defined
- Budget allocated
- Main channels identified
- Resources committed

**Score 3 (Rather not):**
- Basic GTM plan
- Limited budget
- Channels identified but not tested
- Resource gaps

**Score 2 (Not at all):**
- No clear GTM plan
- Minimal budget
- Channels undefined
- Significant resource gaps

**Score 1 (Don't know):**
- GTM not yet planned
- Resource requirements unknown

**Evidence Examples:**
- Go-to-market plan
- Marketing and sales budget
- Channel strategy with access confirmed
- CAC analysis
- Sales team or agency agreements

---

## Dimension Mapping

### Question-to-Dimension Alignment

| Dimension | Questions | Focus Area |
|-----------|-----------|------------|
| **LEGITIMACY** | Q8, Q13 | Foundation and Problem Validation |
| **DESIRABILITY** | Q2, Q4, Q5, Q6, Q7, Q9, Q11, Q12, Q21, Q22, Q25, Q28 | Customer Needs and Market Fit |
| **ACCEPTABILITY** | Q3, Q10, Q17, Q20, Q23, Q24 | Ecosystem Alignment and Stakeholder Support |
| **FEASIBILITY** | Q1, Q15, Q16, Q18, Q26 | Technical and Operational Viability |
| **VIABILITY** | Q14, Q19, Q27, Q29 | Business Model Sustainability and Financial Health |

### Dimension-Level Scoring

**LEGITIMACY Score:** Average of Q8, Q13
**DESIRABILITY Score:** Average of Q2, Q4, Q5, Q6, Q7, Q9, Q11, Q12, Q21, Q22, Q25, Q28
**ACCEPTABILITY Score:** Average of Q3, Q10, Q17, Q20, Q23, (5-Q24) *[Q24 is reverse-scored]*
**FEASIBILITY Score:** Average of Q1, Q15, Q16, Q18, Q26
**VIABILITY Score:** Average of Q14, Q19, Q27, Q29

**Overall Vianeo Score:** Average of all 5 dimension scores

---

## Scoring and Interpretation

### Dimension-Level Interpretation

**Score 4.0-5.0:** Strong validation - dimension well-addressed with evidence
**Score 3.0-3.9:** Adequate validation - dimension addressed with some gaps
**Score 2.0-2.9:** Weak validation - significant work needed
**Score 1.0-1.9:** Critical gap - dimension not addressed or unknown

### Vianeo Framework Targets

**Competitive Submission:** All dimensions ≥ 3.0, overall ≥ 3.5
**Strong Submission:** All dimensions ≥ 3.5, overall ≥ 4.0
**Exceptional Submission:** All dimensions ≥ 4.0, overall ≥ 4.5

### Dimensional Balance

**Well-Balanced Project:** All dimensions within 0.5 points
**Imbalanced Project:** 1.0+ point spread between highest and lowest

**Common Imbalances:**
- Strong Feasibility, Weak Desirability = "Solution looking for a problem"
- Strong Desirability, Weak Viability = "Great idea, unclear business model"
- Strong Legitimacy/Desirability, Weak Acceptability = "Market need but ecosystem resistance"

### Priority Actions by Score

**Dimension Score < 2.0:**
- Immediate research required
- Critical gap must be addressed before progression
- Consider external support or advisory

**Dimension Score 2.0-2.9:**
- Systematic validation work needed
- Allocate dedicated resources
- Plan 4-8 weeks of focused work

**Dimension Score 3.0-3.9:**
- Refinement and additional evidence
- Targeted validation (3-5 additional interviews)
- Documentation improvement

**Dimension Score ≥ 4.0:**
- Maintain and document
- Ongoing monitoring
- Leverage as strength in submissions

---

## Evidence-Based Scoring Guidance

### General Interpretation

**High Confidence (5):**
- Multiple validated sources
- Documented evidence
- External validation (not just internal team view)
- Quantitative data where possible

**Moderate Confidence (4):**
- Some validation
- Internal confirmation
- Preliminary evidence
- Qualitative data with patterns

**Low Confidence (3):**
- Assumptions made
- Limited testing
- Hypothesis stage
- Anecdotal evidence

**Minimal Progress (2):**
- Aware of need but not addressed
- No concrete work
- Speculation only
- Planned but not started

**Unknown (1):**
- Information gap
- Requires investigation
- Not yet considered
- No data available

### Validation Thresholds

**Questions requiring customer validation (Q7, Q19, Q22):**
- Score 5: 10+ validations
- Score 4: 5-9 validations
- Score 3: 3-4 validations
- Score 2: 1-2 validations
- Score 1: No validations

**Questions requiring market analysis (Q3, Q6, Q20):**
- Score 5: Comprehensive mapping completed with validation
- Score 4: Good analysis with some gaps
- Score 3: Basic analysis, not comprehensive
- Score 2: Superficial awareness
- Score 1: Not analyzed

**Questions requiring internal readiness (Q1, Q16, Q26):**
- Score 5: Resources committed and secured
- Score 4: Key resources in place
- Score 3: Some resources, gaps identified
- Score 2: Significant resource gaps
- Score 1: Resources not assessed

**Questions requiring strategic clarity (Q4, Q9, Q27):**
- Score 5: Documented, tested, validated with customers
- Score 4: Documented and validated internally
- Score 3: Documented but not validated
- Score 2: Rough ideas, not documented
- Score 1: Not defined

---

## Best Practices for Completing Assessment

### Pre-Assessment Preparation

1. **Gather Evidence:**
   - Collect interview transcripts, surveys, research reports
   - Compile ecosystem mapping and competitive analysis
   - Review financial models and business plans
   - Assemble resource inventory and commitments

2. **Organize by Dimension:**
   - Group evidence by Vianeo dimension
   - Identify gaps before starting assessment
   - Plan additional research for critical gaps

3. **Set Honest Baseline:**
   - Default to conservative scores when uncertain
   - Use "Don't know" (1) when appropriate
   - Remember: Identifying gaps is valuable

### During Assessment

1. **Evidence-Based Scoring:**
   - Score based on actual evidence, not aspirations
   - Document evidence source for each score
   - Note confidence level in scoring

2. **Use Scoring Guidance:**
   - Refer to detailed scoring criteria for each question
   - Apply validation thresholds consistently
   - Maintain scoring standards across questions

3. **Track Gaps:**
   - List missing evidence as you go
   - Prioritize gaps by dimension
   - Note quick wins vs. major research needs

### Post-Assessment Actions

1. **Calculate Dimension Scores:**
   - Average scores by dimension
   - Identify strongest and weakest dimensions
   - Note dimensional balance

2. **Prioritize Improvements:**
   - Focus on dimensions < 3.0 first
   - Address low-hanging fruit (scores 2.5-2.9)
   - Build on strengths (scores ≥ 4.0)

3. **Create Action Plan:**
   - Assign specific research tasks to team members
   - Set timeline for re-assessment (typically 4-8 weeks)
   - Track progress against improvement goals

4. **Document and Share:**
   - Share assessment results with team and advisors
   - Use as basis for milestone planning
   - Integrate with other validation frameworks (40-Question Diagnostic)

---

## Integration with Other Vianeo Tools

### Complementary Assessments

**40-Question Diagnostic Scan:**
- Internal project maturity focus
- Use in parallel with 29-Question for complete view
- Diagnostic = Team/Tech/Ops readiness, 29-Question = Market readiness

**Sprint Execution Guide:**
- Use assessment results to identify common pitfalls
- Refer to guide for solutions to low-scoring areas
- Avoid pitfalls documented in execution guide

**Needs Qualification Matrix:**
- Use to support Desirability dimension scoring
- Systematically evaluate importance × satisfaction
- Provides evidence for Q2, Q7, Q28

**Platform Character Limits:**
- Use when preparing Vianeo submission based on assessment
- Ensures content fits platform requirements
- Reference when documenting evidence concisely

### Recommended Workflow

1. **Baseline Assessment:** Complete 29-Question and 40-Question assessments
2. **Gap Identification:** Use results to identify research priorities
3. **Validation Sprint:** Execute targeted research (use Sprint Execution Guide)
4. **Re-Assessment:** Complete assessments again after validation work
5. **Submission Prep:** Use Platform Character Limits for final Vianeo entry

---

**Document Version:** 1.0
**Last Updated:** November 2025
**Part of:** Vianeo Business Validation Framework
**Related Documents:** 40-Question Diagnostic Scan, Sprint Execution Guide, Needs Qualification Matrix, Platform Character Limits
